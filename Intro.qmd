---
title: "Why Statistics?"
subtitle: |
   | Basic Statistics Workship 
   | ReTune Fall School   
   | 17th of October, 2025
author: "Dr. Lea Hildebrandt"
format: 
  revealjs:
    smaller: true
    scrollable: true
    slide-number: true
    theme: serif
    chalkboard: true
    width: 1280
    height: 720
execute:
  engine: knitr
from: markdown+emoji
---

# Welcome!

```{css}
code.sourceCode {
  font-size: 1.4em;
}

div.cell-output-stdout {
  font-size: 1.4em;
}
```

## Hello!

Who am I?

. . .

Who are you?

-   What is your background?

-   Do you have experience with data analysis?

-   What's your attitude towards statistics? Statistical confessions?

```{=html}
<!-- . . .

Today, I'm feeling...

![](images/moodmeter_en.jpg){fig-alt="Moodmeter"} -->
```
## What to expect today?

-   Slides can be found here: <https://hillea.github.io/BasicStats-Retune/>

-   Textbooks this workshop is based on/that can be used to read up:

    -   [Learning Statistics with Jamovi](https://davidfoxcroft.github.io/lsj-book/01-Why-do-we-learn-statistics.html)

    -   [Statistical Thinking for the 21st Century](https://statsthinking21.github.io/statsthinking21-core-site/)

    -   [Statistics Done Wrong](https://www.statisticsdonewrong.com/data-analysis.html)

## Schedule {.scrollable .smaller}

| Time | Topic |
|------|-------|
|      |       |

# Why Statistics?

## Why is it important that YOU know statistics?

::: {.incremental .smaller}
-   You're doing a *PhD*!

    -   Research = Reading & understanding papers (esp. the analyses)
    -   Designing your own experiments, analyze data, interpret results

-   We live in an increasingly data-centric world

    -   Knowing how to wrangle and analyze data is a valuable skill

-   Facts & data literacy matter more than ever!

    -   Fake News, "Lying with stats", Reproducibility Crisis

    -   Being able to call bullshit (<https://www.callingbullshit.org/>)

-   "I only believe in statistics that I doctored myself" ― Winston S. Churchill

    -   However: "It is easy to lie with statistics, but easier to lie without them" ― Frederick Mosteller
:::

![](images/clipboard-3793899018.png){width="163"}

![](images/clipboard-1641481056.png){width="429"}

![[https://www.reuters.com/fact-check/misleading-data-used-claim-covid-vaccines-do-more-harm-than-good-2024-03-21](https://www.reuters.com/fact-check/misleading-data-used-claim-covid-vaccines-do-more-harm-than-good-2024-03-21/?utm_source=chatgpt.com)](images/clipboard-8509855.png)

![](images/clipboard-461873537.png)

<https://en.wikipedia.org/wiki/John_Bohannon#Intentionally_misleading_chocolate_study>

## What is Statistical Thinking?

::: incremental
-   "a systematic way of thinking about how we describe the world and **use data \[to\] make decisions and predictions**, all in the context of the inherent **uncertainty** that exists in the real world." (Poldrack, Preface of ST21)

-   "Statistical thinking is a way of **understanding** a complex world by describing it in relatively **simple terms** that nonetheless capture **essential aspects** of its structure or function, and that also provide us some idea of how **uncertain** we are about that knowledge." (Poldrack, Chapter 1)
:::

::: notes
break down complexity, include uncertainty
:::

## Why is Statistical Thinking Important?

::: incremental
-   data literacy vs. intuition/heuristics/anecdotal evidence
    -   Public discourse about Covid-19, migration, etc. (e.g., "50% of people in intensive care are vaccinated")
:::

. . .

[![Base Rate Fallacy](images/BaseRate.jpg){fig-align="center" width="600"}](https://thedecisionlab.com/biases/base-rate-fallacy)

::: notes
example availability heuristic from book (or any other example where intuition is wrong, i.e. vaccinations/covid...)
:::

## What can Statistics Do For Us?

-   **Describe** patterns by summarizing/breaking down data ("descriptive statistics")

-   **Decide** whether one thing is better than another, given the uncertainty ("inferential statistics")

-   **Predict** how other people would "behave" (generalize to new observations)

::: notes
describe: not useful to look at every single data point/person, but we need s.th. like tendencies/trends...
:::

## The Big Ideas

::: incremental
-   **Learning from data**: Update our beliefs

-   **Aggregation**: How to summarize the data to draw meaningful conclusions?

-   **Uncertainty**: Probabilistic evidence

-   **Sampling from the population**: Which people etc. do we select?
:::

::: notes
ask for every point what I could mean w/ it?

Learning from data: gather new knowledge or even just hypotheses

Aggregation: Can't look at all ind data points, need to find trends etc. (should not go too far! throwing out data)

Uncertainty: stats = tools for making decisions under uncertainty, we can never prove anything but provide evidence, there is no 100% certainty for an outcome

sampling: how do we represent the population? What is the population? how much data do we need? More is better, but payoff decreases...
:::

## Causality

Correlation does not imply causation... but is a hint!

. . .

Example: Smoking = less risk for Parkinson's disease? (<a href="http://dx.doi.org/10.1136/jnnp.45.7.577">Godwin-Austen et al., 1982</a>; <a href="https://doi.org/10.1212/WNL.0b013e3181d55f38">Chen et al., 2010</a>)

. . .

→ confounding factors?

. . .

e.g., individual dopaminergic activity ⇒ addiction & motor function

. . .

Randomized Controlled Trials (RCT) as the solution?

::: notes
RCT: exp control and manipulation, removes confounds if done well\
At least some more causal evidence!

QUESTIONS so far?
:::

## What are Data?

-   What do you think are data?

::: {.incremental .smaller}
-   qualitative vs. quantitative

    -   qualitative?

        -   open questions, descriptions... can potentially be coded into categories

    -   quantitative?

        -   numeric, can be averaged etc.
:::

::: notes
Chat → after showing slide! Come up with examples for "Data"

Collect: Do you have ideas? What are data you encounter in your lives/work etc? What are differences between these data?
:::

## What are Data? (2)

::: {.incremental .smaller}
-   Data types

    -   character/string: text (qualitative)

    -   factors/categories

    -   types of numbers (quantitative)

        -   binary: 0 or 1, TRUE or FALSE (logical)

        -   integers: whole numbers

        -   real numbers: decimals/fractions

-   discrete vs. continuous

    -   discrete: finite set of particular values (0 or 1, scale from 1 to 10)

    -   continuous: real numbers that fall into particular range (e.g., brain activity, visual analoge scale)

-   What data type is *eye color*?
:::

::: notes
eye color can be categorical (e.g., "brown", "blue", "green") or numerical (wave length in nm)
:::

## What is a Data Set?

-   a collection of data

-   usually organized into rows and columns (like an excel spreadsheet)

    -   rows: participants/animals/cells...

    -   columns: **variables**!

        -   each variable contains one type of measurement

    -   table cells = unique observations of variables per participant etc.

![NHANES dataset](images/Dataset.jpg)

::: notes
possibly go through columns and ask for data types?
:::

## What Makes a Good Measurement?

::: {.incremental .smaller}
<!-- -   Discuss! -->

-   What is being measured?

    -   constructs vs. proxies: need to be well-defined! (Difficult)

    -   measurement error

        -   random: e.g., variation in reaction times of same participant across trials

        -   systematic: e.g., miscalibrated eye-tracking device

-   Do we have a "gold standard" to compare the measurement to?
:::

::: notes
Break-Out session: Brainstorm what makes a good vs. bad measurement!

Group work/brainstorm:

-   What are problems?

-   Which kind of errors/when is data NOT good

-   how can we minimize error?
:::

## Reliability

Correlation of a measurement with "itself"

::: {.incremental .smaller}
-   Internal reliability (consistency)

-   Test-retest reliability (stability)

-   Inter-rater reliability (agreement)
:::

. . .

Correlation with other variables can't be higher than reliability (cf., <a href="https://doi.org/10.1080/02643294.2012.753433">Wilmer et al., 2012, Table 1</a>)!

## Validity

Are we measuring the construct we're interested in?

::: incremental
-   Face validity: Does it intuitively make sense? First reality check!

-   Construct validity

    -   convergent validity: Related to similar measures that should measure the same construct

    -   divergent validity: Is it unrelated to other measures?

-   Predictive validity: Is it predictive of other outcomes? (e.g., intelligence & job success)
:::

## Validity & Reliability

![Reliability & Validity](images/ReliabilityValidity-1.png){width="400"}

## Summarizing Data

::: {.incremental .smaller}
-   Throwing away (some of the) information!

    -   extract the quintessence of the data (important for forming *models*)

    -   make predictions

-   Counts, frequencies, percentages, averages
:::

# End of 1st part {.scrollable}

Learning objectives:

-   Why is statistics important?

-   What are data?

-   What is reliability and validity?

. . .

Next:

-   Getting started with Jamovi
