---
title: "Correlation, T-Tests & ANOVA in Jamovi"
subtitle: |
   | Basic Statistics Workshop 
   | ReTune Fall School   
   | 17th of October, 2025
author: "Dr. Lea Hildebrandt"
format: 
  revealjs:
    smaller: true
    scrollable: true
    slide-number: true
    theme: serif
    chalkboard: true
    width: 1280
    height: 720
from: markdown+emoji
---

# Statistical Analyses

There are a variety of different statistical tests. The choice depends on the nature of your predictor and outcome variables. It might seem a bit overwhelming, but the underlying idea is very similar.

|   | Outcome |   |
|------------------------|------------------------|------------------------|
| **Predictor** | *continuous* | *categorical* |
| *continuous* | e.g. **correlation**, linear model/regression | e.g. generalized linear model/logistic regression |
| *categorical* | e.g. **t-test, ANOVA**, linear model | e.g. Chi\^2-test |

Due to time constraints, we will focus on the tests often used in published papers (printed in bold).

## Correlation

Correlations are used if you have two continuous variables and you want to check whether they have a relationship (regardless of whether one might have caused the other).

. . .

Running a correlation analysis, we test whether two variables co-vary,[^1] i.e. if one is high, the other variable also tends to be high (or, the opposite, low).

[^1]: $$
    r = \frac{covariance}{s_xs_y} = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{(N - 1)s_x s_y}
    $$

    The numerator represents the covariance between x and y, the denominator is for standardizing the measure by both SDs.

The correlation coefficient *r* can be between -1 (perfect negative correlation) and 1 (perfect positive correlation).

![](images/clipboard-2024951202.png){width="541"}

## Correlations in Jamovi

Let's have a look at how to calculate correlation analyses in Jamovi.

Click on the Analyses tab "Regression" and then "Correlation Matrix". You can now select two variables by adding them to the right box.

You can also select whether you want to include a visualization of the correlation.

![](images/clipboard-3741192376.png){width="626"}

## Interpreting Correlations

Interpreting the r statistic is a bit difficult and it depends on the field and context whether a certain correlation is strong or not. One rule of thumb is the following:

![](images/clipboard-2269899978.png)

## Spearman's Rank Correlation

So far, we have used the Pearson's correlation coefficient, which is by far the most used one. However, we can only use this correlation if the relationship between variables is expected to be linear!

. . .

Study hours, for example, could also be related to exam score non-linearly: The first hours studied help a lot in increasing your grade, but to get from 99% to 100% might take a lot more work. In such a case (or with ordinal data), we would rather use the **Spearman Rank Correlation**.

. . .

For this analysis, Jamovi doesn't use the raw data but ranks them in order and uses these ranks. If participant 1 was the person with the most study hours and the best exam score, they would be rank 1 for both variables. Subsequently, the ranks are correlated.

## Reporting Correlations

We usually report the correlation coefficient (e.g. *r*) with the degrees of freedom and the *p*-value:

`r(98) = .673, p < .001`

## T-Tests

```{css}
code.sourceCode {
  font-size: 1.4em;
}

div.cell-output-stdout {
  font-size: 1.4em;
}
```

Often, we want to know whether two groups (treatment vs. control, men vs. women...) differ on some measure.

In other words, our outcome variables are continuous (e.g. exam scores) and we're interested in the effect of a categorical predictor.

In this case, a t-test would be our statistical analysis of choice.

. . .

There are different kinds of t-tests, depending on the relationship between the two groups:

-   If the two groups are unrelated, e.g. men and women, we would run an *independent samples t-test*.

-   If the two groups are related, e.g. first and second measurement of the same participants, we would run a *paired-samples t-test*.

-   (Sometimes we just want to compare one group to some specific value, then we'd use the *one-sample t-test*.)

## Independent Samples t-Test

Let's first look at the common situation where we want to compare two groups. We often have two independent groups if participants are randomly assigned to one of two conditions.

**Example Research Question**: Do people who drink a lot of coffee score better on an exam than those who drink less coffee?

. . .

**Hypotheses**:

$H_0$ = High caffeine intake is related to *equal or lower* exam scores than low caffeine intake.\
$H_A$ = High caffeine intake is related to *higher* exam scores than low caffeine intake.

## Computing a 2-Level Factor (Grouping Variable)

If we want to run a t-Test, we first need to define a variable with two levels. Caffeine intake, our grouping variable, has three levels. However, we could argue that "no coffee" could also fall in the "low caffeine intake" group. We thus first have to compute a new variable with only two levels, "low" (including no and low coffee intake) and "high".

**Exercise**: Try to compute a new variable, recoding values to "low" *if* they are non-high.

. . .

![](images/clipboard-2457670649.png)

## Independent Samples t-Test in Jamovi

**Exercise**: Try to figure out how to run an Independent Samples t-Test to test the influence of caffeine intake on exam scores!

. . .

Analysis -\> T-Tests -\> Independent Samples -\> exam_scores as Dependent Variable -\> new caffeine variable as Grouping Variable.

It is good practice to choose Welch's test (because it allows for the SDs of the groups to vary), as well as selecting a directed/one-sided hypothesis if possible.

Also, you should test your assumptions, which is really easy in Jamovi.

Finally, it is a good idea to report the descriptives, mean difference with CI, and effect size as well.

## Reporting an Independent Samples t-Test

> A one-sided Welch's t-Test, testing whether high caffeine intake leads to better exam scores than low caffeine intake, revealed a significant difference (M_diff = 5.42, SE_diff = 2.31) between the two groups (*t*(78.0) = 2.35; *p* = .011, Cohen's *d* = .485). High caffeine intake leads to higher exam scores (M = 70.7, SD = 11.2) than low caffeine intake (M = 65.3, SD = 11.2). All assumptions of the t-Test were met.

## Paired-Samples t-Tests

Often, we measure the same participants twice: E.g. once in the treatment manipulation, once in the control condition (and the order would hopefully be counterbalanced) - or before and intervention and after.

If each participant appears in both groups, we have to use the **paired-samples t-test**.

. . .

**Example Research Question**: Do exam scores decline over time? (This could be due to e.g. a manipulation in between.)

**Hypotheses**:

$H_0$ = Exam scores stay the same or improve in a re-test.\
$H_A$ = Exam scores are lower in a re-test than in the first exam.

## Paired-Samples t-Tests in Jamovi

Obviously, we need to collect data with repeated measures for a paired-samples t-test. Please open the file *WorkshopData_Wide* in Jamovi.

You can now see that there are three columns for the exam scores: pre, mid, and post.

::: aside
Note on **Long vs. wide data:** For a lot of analyses, you'd need the data in *long* format, with several rows per participant. For this t-test in Jamovi, however, you'd need it in *wide* format, which means one row per participant and separate columns for exam scores pre, mid, and post measurements.
:::

. . .

**Exercise**: Try to run a paired-samples t-test comparing pre and post exam scores. We expected post scores to be lower.

. . .

Analyses -\> T-Tests -\> Paired Samples T-Test -\> add Exam_Pre and Exam_Post to the "Paired Variables" Box.

Also select the assumption checks, the correct directed hypothesis, and mean difference, effect size and descriptives. What do you notice?

. . .

The **assumption of normality** seems to be violated - however, the QQ-plot looks okayish (dots fall on line).\
Instead of the Student's t-test, you could run the non-parametric alternative, which is the **Wilcoxon rank test** and is independent of the assumption of normality.

This tests whether the median (ranked) difference between paired observations is zero.

## Reporting a Paired-Samples t-Test

**Exercise**: How would you report the result?

. . .

> In contrast to what we expected, post exam scores were not lower than pre exam scores but rather higher (M_post = 73.8, SD_post = 11.7; M_pre = 67.1, SD_pre = 11.4). The one-sided paired-samples t-test was not significant (*t*(99) = -16.1; *p* = .999; M_diff = -6.66; SE_diff = 0.41, Cohen's *d* = -1.61).

Alternatively:

> In contrast to what we expected, post exam scores were not lower than pre exam scores but rather higher (Median_post = 73.0; Median_pre = 67.7). The assumption of normality was violated, which is why a Wilcoxon rank test was conducted. This one-sided t-test was not significant (*W* = 25.0; *p* = .999; *r* = -.99).

# Comparing Several Means: ANOVA

Often, we either have more than two groups we want to compare and/or more than two predictor/grouping variables.

Let's assume we want to not only compare "low" to "high" caffeine intake, but do want to account for those who drink no coffee at all. In this case, we thus want to compare three groups.

. . .

To do so, we would run a **one-way Analysis of Variance (ANOVA)**, which should be used if we have only one grouping variable with more than two levels.

## One-Way Analysis of Variance

With ANOVAs, we generally test whether there are differences between the groups, but not directly which groups differ from each other. (Spoiler: To do so, we need to run follow-up (t-)tests.)

In other words, our null hypothesis would be that e.g. caffeine has no effect on scores and all groups score the same:

$
H_0 = mean_a == mean_b == mean_c 
$

In contrast, the alternative hypothesis would be:

$
H_a = 
$not all means are equal

## Analysis of *Variance*?

Although we want to compare means of the groups to test the hypothesis, the *variance* is important for this (slightly more complex) statistical test.

There are different relevant variences, *between-group* and *within-group:*

![](images/clipboard-3164202396.png)

::: notes
\[variance –\> sum of squares –\> F\]
:::

## One-Way ANOVA in Jamovi
